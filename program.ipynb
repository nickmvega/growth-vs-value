{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import yfinance as yf\n",
    "from fredapi import Fred\n",
    "\n",
    "FRED_API_KEY = 'c8ffb85d56a65bb030644d9d02528564'\n",
    "fred = Fred(api_key=FRED_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker, start_date=\"2000-11-13\", end_date=\"2022-12-30\"):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    stock_data = stock.history(start=start_date, end=end_date, interval=\"1d\")\n",
    "    # Keep the 'Close', 'High', 'Low', etc., without calculating the percentage change\n",
    "    columns_to_keep = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    stock_data = stock_data[columns_to_keep]\n",
    "    \n",
    "    stock_data.index = pd.to_datetime(stock_data.index)\n",
    "    return stock_data.resample('Q').ffill()\n",
    "\n",
    "\n",
    "\n",
    "def fetch_fred_data(indicators, start_date):\n",
    "    fred = Fred(api_key=FRED_API_KEY)\n",
    "    dfs = []\n",
    "\n",
    "    for series_id in indicators:\n",
    "        data = fred.get_series(series_id, start_date)\n",
    "        df = pd.DataFrame({f\"{series_id}\": data})\n",
    "        dfs.append(df)\n",
    "\n",
    "    result_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "    result_df.ffill(inplace=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_velocity(data, window=10):\n",
    "    data['Velocity'] = data['Close'].pct_change() * 100 \n",
    "    data['Velocity'] = data['Velocity'].rolling(window=window).mean()\n",
    "    return data\n",
    "\n",
    "def calculate_magnitude(data, window=10):\n",
    "    if 'High' in data.columns and 'Low' in data.columns:\n",
    "        data['Magnitude'] = data['High'] - data['Low']\n",
    "        data['Magnitude'] = data['Magnitude'].rolling(window=window).mean()\n",
    "    else:\n",
    "        print(\"Missing 'High' or 'Low' columns in DataFrame.\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_economic_data_column(data, economic_data):\n",
    "    if data.index.tz is not None:\n",
    "        data.index = data.index.tz_localize(None)\n",
    "    \n",
    "    for series_id in economic_data.columns:\n",
    "        economic_data_series = economic_data[series_id]\n",
    "        if economic_data_series.index.tz is not None:\n",
    "            economic_data_series = economic_data_series.tz_localize(None)\n",
    "        \n",
    "        economic_data_series = economic_data_series.reindex(data.index, method='ffill')\n",
    "        data[f\"{series_id}\"] = economic_data_series\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_target_column(data, horizon=1):\n",
    "    data[\"Future_Close\"] = data[\"Close\"].shift(-horizon * 3)\n",
    "    data[\"Target\"] = (data[\"Future_Close\"] > data[\"Close\"]).astype(int)\n",
    "    data = data.dropna(subset=[\"Target\"])\n",
    "    return data\n",
    "\n",
    "def generate_features(data, horizons):\n",
    "    new_predictors = []\n",
    "\n",
    "    for horizon in horizons:\n",
    "        rolling_averages = data[\"Close\"].rolling(horizon).mean()\n",
    "\n",
    "        ratio_column = f\"Close_Ratio_{horizon}\"\n",
    "        data[ratio_column] = data[\"Close\"] / rolling_averages\n",
    "\n",
    "        trend_column = f\"Trend_{horizon}\"\n",
    "        data[trend_column] = data.shift(1).rolling(horizon).sum()[\"Target\"]\n",
    "\n",
    "        new_predictors += [ratio_column, trend_column]\n",
    "\n",
    "    data = data.dropna(subset=data.columns[data.columns != \"Target\"])\n",
    "    return data, new_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(ticker, series_ids, date):\n",
    "    stock_data = fetch_stock_data(ticker, start_date=date)\n",
    "    economic_data = fetch_fred_data(series_ids, date)\n",
    "\n",
    "    # Ensure both stock and economic data have the correct timezones\n",
    "    if stock_data.index.tz is not None:\n",
    "        stock_data.index = stock_data.index.tz_localize(None)\n",
    "    if economic_data.index.tz is not None:\n",
    "        economic_data.index = economic_data.index.tz_localize(None)\n",
    "\n",
    "    # Incorporate economic data\n",
    "    stock_data = create_economic_data_column(stock_data, economic_data)\n",
    "\n",
    "    # Prepare stock data with additional features\n",
    "    stock_data = calculate_magnitude(stock_data)\n",
    "    stock_data = calculate_velocity(stock_data)\n",
    "    \n",
    "    # Create the Target column before generating features\n",
    "    stock_data = create_target_column(stock_data, horizon=1)\n",
    "\n",
    "    # Generate features based on horizons and include economic data\n",
    "    stock_data, new_predictors = generate_features(stock_data, [10, 20, 30])\n",
    "\n",
    "    return stock_data, new_predictors + list(economic_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(ticker, series_ids, date=\"2000-11-13\", threshold=0.5):\n",
    "    data, new_predictors = combine_data(ticker, series_ids, date)\n",
    "    if data.empty:\n",
    "        print(f\"No data available for {ticker}. Cannot proceed with prediction.\")\n",
    "        return None\n",
    "\n",
    "    # Define predictors: Ensure this list includes the features you intend to use\n",
    "    predictors = new_predictors + ['Magnitude', 'Velocity']\n",
    "\n",
    "    # Prepare X, y for modeling. Use 'Target' directly since 'ticker_pct_change' is not used\n",
    "    X = data[predictors].dropna()\n",
    "    y = data['Target']\n",
    "\n",
    "    # Note: The shift of y is removed since 'Target' already accounts for future movement\n",
    "    if len(X) < 1 or len(y) < 1:\n",
    "        print(\"Not enough data for training and prediction.\")\n",
    "        return None\n",
    "\n",
    "    # Split data, train model, and predict\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict for the latest data available\n",
    "    latest_data = X.iloc[[-1]]  # Correct syntax\n",
    "\n",
    "    # Use predict_proba to get the probability of the \"invest\" class\n",
    "    probabilities = model.predict_proba(latest_data)\n",
    "    invest_proba = probabilities[:, 1]  # Assuming class 1 corresponds to \"invest\"\n",
    "\n",
    "    if invest_proba[0] < threshold:\n",
    "        decision = \"Do not invest\"\n",
    "    else:\n",
    "        decision = \"Invest\"\n",
    "\n",
    "    return decision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIVIX: Invest\n",
      "VIGAX: Do not invest\n"
     ]
    }
   ],
   "source": [
    "important_series = [\n",
    "    \"CPIAUCNS\",  # Consumer price index\n",
    "    \"FEDFUNDS\",  # Federal funds interest rate\n",
    "    \"GS10\",      # 10-Year treasury yield\n",
    "    \"M2\",        # Money stock measures\n",
    "    \"MICH\",      # UMich: inflation expectation\n",
    "    \"UMCSENT\",   # UMich: consumer sentiment\n",
    "    \"UNRATE\"    # Unemployment rate\n",
    "]\n",
    "\n",
    "threshold = 0.5 \n",
    "prediction_vivix = train_and_predict(\"VIVIX\", important_series, \"2000-11-13\", threshold)\n",
    "prediction_vigax = train_and_predict(\"VIGAX\", important_series, \"2000-11-13\", threshold)\n",
    "\n",
    "print(f\"VIVIX: {prediction_vivix}\")\n",
    "print(f\"VIGAX: {prediction_vigax}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
